{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 13:12:52.814140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-29 13:12:53.062681: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-29 13:12:53.118448: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yonix42/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-07-29 13:12:53.118460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-29 13:12:53.159503: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-29 13:12:53.979242: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yonix42/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-07-29 13:12:53.979306: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yonix42/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-07-29 13:12:53.979311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/yonix42/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/yonix42/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/yonix42/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/yonix42/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/yonix42/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/yonix42/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import keras\n",
    "import joblib\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns2:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "\n",
    "    def describe(self, image, eps=1e-7):\n",
    "        lbp = local_binary_pattern(\n",
    "            image, self.numPoints, self.radius, method=\"nri_uniform\")\n",
    "        n_bins = int(lbp.max() + 1)\n",
    "        (hist, _) = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = LocalBinaryPatterns2(8, 2)\n",
    "\n",
    "labels = []\n",
    "images = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "path = './spec_evaluation_janela_completo/'\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "classes = [\"beach\", \"bus\", \"cafe_restaurant\", \"car\", \"city_center\", \"forest_path\", \"grocery_store\",\n",
    "           \"home\", \"library\", \"metro_station\", \"office\", \"park\", \"residential_area\", \"train\", \"tram\"]\n",
    "\n",
    "max_imagens = 390\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(max_imagens):\n",
    "    if j == 26:\n",
    "        j = 0\n",
    "        k += 1\n",
    "    path_total = path + 'class_' + classes[k] + '/'\n",
    "    \n",
    "    path_img = path_total + str(i) + '.png'\n",
    "    img_rgb = cv2.imread(path_img)\n",
    "    img_rgb = cv2.resize(img_rgb, (256, 256))\n",
    "    images.append(img_rgb)\n",
    "\n",
    "    img_gray = cv2.imread(path_img, 0)\n",
    "    hist = desc.describe(img_gray)\n",
    "    X.append(hist)\n",
    "\n",
    "    labels.append(k)\n",
    "    j += 1\n",
    "\n",
    "y = labels[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 13:13:50.019404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yonix42/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-07-29 13:13:50.019657: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-29 13:13:50.019671: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (staub): /proc/driver/nvidia/version does not exist\n",
      "2023-07-29 13:13:50.020212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVC from version 1.2.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_path = './saida2/'\n",
    "\n",
    "json_file = open(model_path+'model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.load_weights(model_path+'model.h5')\n",
    "\n",
    "loaded_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "svm_model = joblib.load(model_path+'modelo_svm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 7s 477ms/step\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "predicoes_cnn = loaded_model.predict(images)\n",
    "predicoes_svm = svm_model.predict_proba(X)\n",
    "predicoes_real = y[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borda_count(svm_preds, cnn_preds):\n",
    "    bordas = np.abs(svm_preds - cnn_preds)\n",
    "\n",
    "    return np.argmax(bordas, axis=1)\n",
    "\n",
    "def soma_simples(svm_preds, cnn_preds):\n",
    "    preds_compinadas = svm_preds + cnn_preds\n",
    "\n",
    "    return np.argmax(preds_compinadas, axis=1)\n",
    "\n",
    "def produto(svm_preds, cnn_preds):\n",
    "    preds_compinadas = svm_preds * cnn_preds\n",
    "\n",
    "    return np.argmax(preds_compinadas, axis=1)\n",
    "\n",
    "\n",
    "def media_simples(svm_preds, cnn_preds):\n",
    "    preds_combinadas = (svm_preds + cnn_preds) / 2.0\n",
    "\n",
    "    return np.argmax(preds_combinadas, axis=1)\n",
    "\n",
    "def media_ponderada(svm_preds, cnn_preds, peso_svm, peso_cnn):\n",
    "    preds_combinadas = (peso_svm * svm_preds + peso_cnn *\n",
    "                        cnn_preds) / (peso_svm + peso_cnn)\n",
    "\n",
    "    return  np.argmax(preds_combinadas, axis=1)\n",
    "\n",
    "def maiores_valores(svm_preds, cnn_preds):\n",
    "    fusion_preds = np.maximum(svm_preds, cnn_preds)\n",
    "\n",
    "    return  np.argmax(fusion_preds, axis=1)\n",
    "\n",
    "def maioria_ponderada(svm_preds, cnn_preds, peso_svm, peso_cnn):\n",
    "    fusion_preds = peso_svm * svm_preds + peso_cnn * cnn_preds\n",
    "\n",
    "    classes_preditas = np.argmax(fusion_preds, axis=1)\n",
    "\n",
    "    return classes_preditas\n",
    "\n",
    "def fusao_com_rejeicao(svm_preds, cnn_preds, limiar_rejeicao=0.4):\n",
    "    votos_totais = svm_preds + cnn_preds\n",
    "    previsoes_finais = np.argmax(votos_totais, axis=1)\n",
    "    confianca = np.max(votos_totais, axis=1)\n",
    "    previsoes_finais[confianca < limiar_rejeicao] = -1  \n",
    "    return previsoes_finais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_borda_count: 0.2641025641025641\n",
      "acc_soma_simples: 0.2743589743589744\n",
      "acc_produto: 0.3564102564102564\n",
      "acc_media_simples: 0.2743589743589744\n",
      "acc_media_ponderada: 0.6076923076923076\n",
      "acc_maiores_valores: 0.2717948717948718\n",
      "acc_maioria_ponderada: 0.5897435897435898\n",
      "acc_fusao_com_rejeicao: 0.258974358974359\n",
      "O melhor método é o Média Ponderada com acuracia de 0.6076923076923076\n"
     ]
    }
   ],
   "source": [
    "nomes_metodos = ['Votação por Borda', 'Soma Simples', 'Produto', 'Média Simples',\n",
    "                 'Média Ponderada', 'Maiores Valores', 'Maioria Ponderada', \n",
    "                 'Fusao com rejeicao']\n",
    "\n",
    "lista_acuracia = np.array([])\n",
    "\n",
    "preds_teste = borda_count(predicoes_svm, predicoes_cnn)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_borda_count:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = soma_simples(predicoes_svm, predicoes_cnn)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_soma_simples:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = produto(predicoes_svm, predicoes_cnn)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_produto:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = media_simples(predicoes_svm, predicoes_cnn)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_media_simples:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = media_ponderada(predicoes_svm, predicoes_cnn, 2, 8)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_media_ponderada:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = maiores_valores(predicoes_svm, predicoes_cnn)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_maiores_valores:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = maioria_ponderada(predicoes_svm, predicoes_cnn, 1, 2)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_maioria_ponderada:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "preds_teste = fusao_com_rejeicao(predicoes_svm, predicoes_cnn, limiar_rejeicao=0.8)\n",
    "acc_aux = accuracy_score(predicoes_real, preds_teste)\n",
    "print(\"acc_fusao_com_rejeicao:\", acc_aux)\n",
    "lista_acuracia = np.append(lista_acuracia, acc_aux)\n",
    "\n",
    "melhor_metodo = np.argmax(lista_acuracia)\n",
    "melhor_acuracia = lista_acuracia[melhor_metodo]\n",
    "nome_melhor_metodo = nomes_metodos[melhor_metodo]\n",
    "\n",
    "print(f'O melhor método é o {nome_melhor_metodo} com acuracia de {melhor_acuracia}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
